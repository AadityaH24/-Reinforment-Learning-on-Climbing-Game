

--25th/04
13:37
Add custom config file. give command mlagents-learn <trainer-config-file> --env=<env_name> --run-id=<run-identifier> to train based on file
Current changes:
    made recording steps 10,000 so results and graph on  tensorboard is in 10k incrments instaed of 50ks
    run id = test2

14:06 Model seemed to get stuck on rock. unsure why it didnt reset(time based episode end doesnt seem to work)
    using config de2.yaml. changed episolon decay schedule to constant
    Tried to ensure time based reset is working. It is. unsure why agent got stuck.
    id = debug1

14:20 start with def2 again 
    id = test4
    model seemed to have learned to just chill on top of own stick
    after sometime

14:50 use default3 yaml but with algorithm ppo->sac
    id = sac1
    unity crashed uh oh
    now using batch size of 256 and a buffer size of 1000000
    new id = sac2
    very slow but it runs

--26th/04
10:42 changed only the AgentScript.cs file
    id = neg1
    Changed reward at every time step to 0.4 * xpos + 06 * ypos - 100

20:31 made new scene that is a copy of current scene and placed agent between two rocks
    running default on this
    agent script for scene 2 is agent Script2
    removed xdir reward
    id = newPpo1
    model didnt move much
    changed max range to 4
    id = newPpo2